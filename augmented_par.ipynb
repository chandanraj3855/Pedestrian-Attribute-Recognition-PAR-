{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"18FoJCG2X9bT-hgfNvqNcI443iTAJxyME","authorship_tag":"ABX9TyNFjV7vT5s2YT7IitotYAS0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install opencv-python-headless Pillow torchvision"],"metadata":{"id":"ClCD0BFBOqJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from PIL import Image, ImageEnhance\n","import torchvision.transforms as transforms\n","from random import randint, uniform\n","\n","def horizontal_flip(image):\n","    return image.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","def rotate(image, angle):\n","    return image.rotate(angle)\n","\n","def scale(image, scale_factor):\n","    width, height = image.size\n","    new_width = int(width * scale_factor)\n","    new_height = int(height * scale_factor)\n","    return image.resize((new_width, new_height), Image.ANTIALIAS)\n","\n","def translate(image, x, y):\n","    return image.transform(image.size, Image.AFFINE, (1, 0, x, 0, 1, y))\n","\n","def color_jitter(image):\n","    enhancer = ImageEnhance.Color(image)\n","    return enhancer.enhance(uniform(0.8, 1.2))\n","\n","def add_noise(image):\n","    np_image = np.array(image)\n","    noise = np.random.randint(0, 50, (np_image.shape[0], np_image.shape[1], 3), dtype='uint8')\n","    np_image = np_image + noise\n","    return Image.fromarray(np.clip(np_image, 0, 255))\n","\n","def shear(image, angle):\n","    return image.transform(image.size, Image.AFFINE, (1, np.tan(np.radians(angle)), 0, 0, 1, 0))\n","\n","def random_augmentation(image):\n","    augmentation_functions = [\n","        horizontal_flip,\n","        lambda img: rotate(img, uniform(-10, 10)),\n","        lambda img: scale(img, uniform(0.9, 1.1)),\n","        lambda img: translate(img, randint(-10, 10), randint(-10, 10)),\n","        color_jitter,\n","        add_noise,\n","        lambda img: shear(img, uniform(-10, 10)),\n","    ]\n","    aug_func = np.random.choice(augmentation_functions)\n","    return aug_func(image)\n"],"metadata":{"id":"xYJo9Kh-JH5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","from PIL import Image, ImageEnhance\n","import numpy as np\n","import torchvision.transforms as transforms\n","\n","# Define augmentation functions\n","def horizontal_flip(image):\n","    return image.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","def rotate(image, angle):\n","    return image.rotate(angle)\n","\n","def scale(image, scale_factor):\n","    width, height = image.size\n","    new_width = int(width * scale_factor)\n","    new_height = int(height * scale_factor)\n","    return image.resize((new_width, new_height), Image.ANTIALIAS)\n","\n","def translate(image, x, y):\n","    return image.transform(image.size, Image.AFFINE, (1, 0, x, 0, 1, y))\n","\n","def color_jitter(image):\n","    enhancer = ImageEnhance.Color(image)\n","    return enhancer.enhance(random.uniform(0.8, 1.2))\n","\n","def add_noise(image):\n","    np_image = np.array(image)\n","    noise = np.random.randint(0, 50, (np_image.shape[0], np_image.shape[1], 3), dtype='uint8')\n","    np_image = np_image + noise\n","    return Image.fromarray(np.clip(np_image, 0, 255))\n","\n","def shear(image, angle):\n","    return image.transform(image.size, Image.AFFINE, (1, np.tan(np.radians(angle)), 0, 0, 1, 0))\n","\n","# List of augmentation functions\n","augmentation_functions = [\n","    horizontal_flip,\n","    lambda img: rotate(img, random.uniform(-10, 10)),\n","    lambda img: scale(img, random.uniform(0.9, 1.1)),\n","    lambda img: translate(img, random.randint(-10, 10), random.randint(-10, 10)),\n","    color_jitter,\n","    add_noise,\n","    lambda img: shear(img, random.uniform(-10, 10)),\n","]\n","\n","# Apply augmentations\n","def augment_and_save_images(image_dir, output_dir, num_augmentations=10):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for image_name in os.listdir(image_dir):\n","        if image_name.endswith('.jpg'):\n","            image_path = os.path.join(image_dir, image_name)\n","            image = Image.open(image_path)\n","            image_base_name = os.path.splitext(image_name)[0]\n","\n","            for i in range(1, num_augmentations + 1):\n","                augmented_image = random.choice(augmentation_functions)(image)\n","                new_image_name = f\"{image_base_name}.{i}.jpg\"\n","                new_image_path = os.path.join(output_dir, new_image_name)\n","                augmented_image.save(new_image_path)\n","                print(f\"Saved {new_image_path}\")\n","\n","# Directory paths\n","input_directory = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/images'\n","output_directory = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/augmented_images'\n","\n","augment_and_save_images(input_directory, output_directory, num_augmentations=10)\n"],"metadata":{"id":"aeU2oHnxJH_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_dir= '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/augmented_images'\n","num_files = len([name for name in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, name))])\n","print(f\"Total augmented images: {num_files}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BFnzmbWNP8M","executionInfo":{"status":"ok","timestamp":1718728667545,"user_tz":-330,"elapsed":6310,"user":{"displayName":"CHANDAN RAJ","userId":"01959545729343590656"}},"outputId":"44d79266-9a76-460d-a382-fafb8ed98fc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total augmented images: 6000\n"]}]},{"cell_type":"code","source":["input_file = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/train.txt'  # Replace with your input file path\n","output_file = '/content/path_to_your_output_file.txt'  # Replace with your output file path\n","\n","def augment_rows(input_file, output_file, num_copies=10):\n","    with open(input_file, 'r') as infile:\n","        rows = infile.readlines()\n","\n","    augmented_rows = []\n","\n","    for row in rows:\n","        columns = row.strip().split()\n","        name = columns[0]\n","        labels = columns[1:]\n","\n","        for i in range(1, num_copies + 1):\n","            new_name = f\"{name}.{i}\"\n","            new_row = [new_name] + labels\n","            augmented_rows.append(' '.join(new_row))\n","\n","    with open(output_file, 'w') as outfile:\n","        for augmented_row in augmented_rows:\n","            outfile.write(augmented_row + '\\n')\n","\n","augment_rows(input_file, output_file, num_copies=10)\n"],"metadata":{"id":"lQClMvHtJIDr","executionInfo":{"status":"ok","timestamp":1718901259557,"user_tz":-330,"elapsed":1281,"user":{"displayName":"CHANDAN RAJ","userId":"01959545729343590656"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["input_file = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/train.txt'  # Replace with your output file path\n","\n","def count_rows(file_path):\n","    with open(file_path, 'r') as file:\n","        rows = file.readlines()\n","        return len(rows)\n","\n","total_rows = count_rows(output_file)\n","print(f\"Total number of rows in the augmented dataset: {total_rows}\")\n"],"metadata":{"id":"FCvL1-pLOqMm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718729844383,"user_tz":-330,"elapsed":572,"user":{"displayName":"CHANDAN RAJ","userId":"01959545729343590656"}},"outputId":"ca7d27df-3cbb-4aab-d8df-118c847d59a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of rows in the augmented dataset: 6000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4mebnIwjOqQv"},"execution_count":null,"outputs":[]}]}