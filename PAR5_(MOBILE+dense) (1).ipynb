{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision pandas scikit-learn pillow\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define constants\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "NUM_CLASSES = 49\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/'\n",
        "train_path = os.path.join(drive_base_path, 'train.txt')\n",
        "images_folder = os.path.join(drive_base_path, 'images')\n",
        "\n",
        "# Load dataset\n",
        "train_df = pd.read_csv(train_path, sep=' ', header=None)\n",
        "image_names = train_df.iloc[:, 0].astype(str).values\n",
        "labels = train_df.iloc[:, 1:].values.astype(int)\n",
        "\n",
        "# Split dataset\n",
        "image_names_train, image_names_val, labels_train, labels_val = train_test_split(image_names, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_names, labels, images_folder, transform=None):\n",
        "        self.image_names = image_names\n",
        "        self.labels = labels\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.images_folder, f\"{img_name}.jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = CustomDataset(image_names_train, labels_train, images_folder, transform=transform)\n",
        "val_dataset = CustomDataset(image_names_val, labels_val, images_folder, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the DenseNet model\n",
        "class PretrainedDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PretrainedDenseNet, self).__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)\n",
        "\n",
        "# Define the SimpleCNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the models\n",
        "densenet_model = PretrainedDenseNet(NUM_CLASSES).to(DEVICE)\n",
        "simplecnn_model = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# Define the ensemble model\n",
        "class EnsembleModel(nn.Module):\n",
        "    def __init__(self, densenet_model, simplecnn_model):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.densenet_model = densenet_model\n",
        "        self.simplecnn_model = simplecnn_model\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(NUM_CLASSES * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, NUM_CLASSES),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        densenet_output = self.densenet_model(x)\n",
        "        simplecnn_output = self.simplecnn_model(x)\n",
        "        combined_output = torch.cat((densenet_output, simplecnn_output), dim=1)\n",
        "        return self.classifier(combined_output)\n",
        "\n",
        "# Instantiate the ensemble model\n",
        "ensemble_model = EnsembleModel(densenet_model, simplecnn_model).to(DEVICE)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    ensemble_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE).float()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = ensemble_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"ensemble_model.pth\"\n",
        "torch.save(ensemble_model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# Validation\n",
        "# Validation\n",
        "ensemble_model.eval()\n",
        "val_loss = 0.0\n",
        "val_corrects = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in val_loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE).float()\n",
        "        outputs = ensemble_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Binary prediction for multi-label classification\n",
        "        preds = (outputs > 0.5).float()\n",
        "\n",
        "        # Compute correct predictions\n",
        "        val_corrects += (preds == targets).sum().item()\n",
        "\n",
        "# Average loss over validation set\n",
        "val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "# Average accuracy per sample\n",
        "val_accuracy = val_corrects / (len(val_loader.dataset) * NUM_CLASSES)\n",
        "\n",
        "print(f'Validation Loss: {val_loss:.4f}')\n",
        "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbaMSbIdt32L",
        "outputId": "9f3f4b6b-30bc-4573-cbfc-97826a674768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.4926\n",
            "Epoch 2/100, Loss: 0.4026\n",
            "Epoch 3/100, Loss: 0.3922\n",
            "Epoch 4/100, Loss: 0.3873\n",
            "Epoch 5/100, Loss: 0.3821\n",
            "Epoch 6/100, Loss: 0.3748\n",
            "Epoch 7/100, Loss: 0.3720\n",
            "Epoch 8/100, Loss: 0.3640\n",
            "Epoch 9/100, Loss: 0.3614\n",
            "Epoch 10/100, Loss: 0.3576\n",
            "Epoch 11/100, Loss: 0.3528\n",
            "Epoch 12/100, Loss: 0.3572\n",
            "Epoch 13/100, Loss: 0.3541\n",
            "Epoch 14/100, Loss: 0.3511\n",
            "Epoch 15/100, Loss: 0.3521\n",
            "Epoch 16/100, Loss: 0.3488\n",
            "Epoch 17/100, Loss: 0.3491\n",
            "Epoch 18/100, Loss: 0.3447\n",
            "Epoch 19/100, Loss: 0.3433\n",
            "Epoch 20/100, Loss: 0.3413\n",
            "Epoch 21/100, Loss: 0.3399\n",
            "Epoch 22/100, Loss: 0.3416\n",
            "Epoch 23/100, Loss: 0.3410\n",
            "Epoch 24/100, Loss: 0.3377\n",
            "Epoch 25/100, Loss: 0.3392\n",
            "Epoch 26/100, Loss: 0.3444\n",
            "Epoch 27/100, Loss: 0.3401\n",
            "Epoch 28/100, Loss: 0.3392\n",
            "Epoch 29/100, Loss: 0.3335\n",
            "Epoch 30/100, Loss: 0.3367\n",
            "Epoch 31/100, Loss: 0.3338\n",
            "Epoch 32/100, Loss: 0.3317\n",
            "Epoch 33/100, Loss: 0.3341\n",
            "Epoch 34/100, Loss: 0.3294\n",
            "Epoch 35/100, Loss: 0.3353\n",
            "Epoch 36/100, Loss: 0.3338\n",
            "Epoch 37/100, Loss: 0.3263\n",
            "Epoch 38/100, Loss: 0.3262\n",
            "Epoch 39/100, Loss: 0.3277\n",
            "Epoch 40/100, Loss: 0.3250\n",
            "Epoch 41/100, Loss: 0.3286\n",
            "Epoch 42/100, Loss: 0.3239\n",
            "Epoch 43/100, Loss: 0.3257\n",
            "Epoch 44/100, Loss: 0.3230\n",
            "Epoch 45/100, Loss: 0.3220\n",
            "Epoch 46/100, Loss: 0.3228\n",
            "Epoch 47/100, Loss: 0.3247\n",
            "Epoch 48/100, Loss: 0.3254\n",
            "Epoch 49/100, Loss: 0.3257\n",
            "Epoch 50/100, Loss: 0.3238\n",
            "Epoch 51/100, Loss: 0.3251\n",
            "Epoch 52/100, Loss: 0.3235\n",
            "Epoch 53/100, Loss: 0.3241\n",
            "Epoch 54/100, Loss: 0.3210\n",
            "Epoch 55/100, Loss: 0.3183\n",
            "Epoch 56/100, Loss: 0.3173\n",
            "Epoch 57/100, Loss: 0.3157\n",
            "Epoch 58/100, Loss: 0.3170\n",
            "Epoch 59/100, Loss: 0.3139\n",
            "Epoch 60/100, Loss: 0.3116\n",
            "Epoch 61/100, Loss: 0.3084\n",
            "Epoch 62/100, Loss: 0.3129\n",
            "Epoch 63/100, Loss: 0.3125\n",
            "Epoch 64/100, Loss: 0.3129\n",
            "Epoch 65/100, Loss: 0.3097\n",
            "Epoch 66/100, Loss: 0.3108\n",
            "Epoch 67/100, Loss: 0.3065\n",
            "Epoch 68/100, Loss: 0.3107\n",
            "Epoch 69/100, Loss: 0.3163\n",
            "Epoch 70/100, Loss: 0.3093\n",
            "Epoch 71/100, Loss: 0.3103\n",
            "Epoch 72/100, Loss: 0.3072\n",
            "Epoch 73/100, Loss: 0.3053\n",
            "Epoch 74/100, Loss: 0.3084\n",
            "Epoch 75/100, Loss: 0.3109\n",
            "Epoch 76/100, Loss: 0.3115\n",
            "Epoch 77/100, Loss: 0.3094\n",
            "Epoch 78/100, Loss: 0.3025\n",
            "Epoch 79/100, Loss: 0.3023\n",
            "Epoch 80/100, Loss: 0.3021\n",
            "Epoch 81/100, Loss: 0.3032\n",
            "Epoch 82/100, Loss: 0.2994\n",
            "Epoch 83/100, Loss: 0.3031\n",
            "Epoch 84/100, Loss: 0.2989\n",
            "Epoch 85/100, Loss: 0.3041\n",
            "Epoch 86/100, Loss: 0.3003\n",
            "Epoch 87/100, Loss: 0.2974\n",
            "Epoch 88/100, Loss: 0.2945\n",
            "Epoch 89/100, Loss: 0.2954\n",
            "Epoch 90/100, Loss: 0.2969\n",
            "Epoch 91/100, Loss: 0.3003\n",
            "Epoch 92/100, Loss: 0.2961\n",
            "Epoch 93/100, Loss: 0.2966\n",
            "Epoch 94/100, Loss: 0.2994\n",
            "Epoch 95/100, Loss: 0.2939\n",
            "Epoch 96/100, Loss: 0.2961\n",
            "Epoch 97/100, Loss: 0.2928\n",
            "Epoch 98/100, Loss: 0.2905\n",
            "Epoch 99/100, Loss: 0.2970\n",
            "Epoch 100/100, Loss: 0.2928\n",
            "Model saved to ensemble_model.pth\n",
            "Validation Loss: 0.3748\n",
            "Validation Accuracy: 0.8517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision pandas scikit-learn pillow\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define constants\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "NUM_CLASSES = 49\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 500\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/'\n",
        "train_path = os.path.join(drive_base_path, 'train.txt')\n",
        "images_folder = os.path.join(drive_base_path, 'images')\n",
        "\n",
        "# Load dataset\n",
        "train_df = pd.read_csv(train_path, sep=' ', header=None)\n",
        "image_names = train_df.iloc[:, 0].astype(str).values\n",
        "labels = train_df.iloc[:, 1:].values.astype(int)\n",
        "\n",
        "# Split dataset\n",
        "image_names_train, image_names_val, labels_train, labels_val = train_test_split(image_names, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_names, labels, images_folder, transform=None):\n",
        "        self.image_names = image_names\n",
        "        self.labels = labels\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.images_folder, f\"{img_name}.jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = CustomDataset(image_names_train, labels_train, images_folder, transform=transform)\n",
        "val_dataset = CustomDataset(image_names_val, labels_val, images_folder, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the DenseNet model\n",
        "class PretrainedDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PretrainedDenseNet, self).__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)\n",
        "\n",
        "# Define the SimpleCNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the models\n",
        "densenet_model = PretrainedDenseNet(NUM_CLASSES).to(DEVICE)\n",
        "simplecnn_model = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# Define the ensemble model\n",
        "class EnsembleModel(nn.Module):\n",
        "    def __init__(self, densenet_model, simplecnn_model):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.densenet_model = densenet_model\n",
        "        self.simplecnn_model = simplecnn_model\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(NUM_CLASSES * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, NUM_CLASSES),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        densenet_output = self.densenet_model(x)\n",
        "        simplecnn_output = self.simplecnn_model(x)\n",
        "        combined_output = torch.cat((densenet_output, simplecnn_output), dim=1)\n",
        "        return self.classifier(combined_output)\n",
        "\n",
        "# Instantiate the ensemble model\n",
        "ensemble_model = EnsembleModel(densenet_model, simplecnn_model).to(DEVICE)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    ensemble_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE).float()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = ensemble_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    ensemble_model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE).float()\n",
        "            outputs = ensemble_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Binary prediction for multi-label classification\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            # Compute correct predictions\n",
        "            val_corrects += (preds == targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_accuracy = val_corrects / (len(val_loader.dataset) * NUM_CLASSES)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"ensemble_model.pth\"\n",
        "torch.save(ensemble_model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF9onwD_zTbp",
        "outputId": "b736a0ef-e621-4cb7-aba2-f416fc7dba54"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 0.4960, Validation Loss: 0.4050, Validation Accuracy: 0.8350\n",
            "Epoch 2/500, Loss: 0.3998, Validation Loss: 0.3869, Validation Accuracy: 0.8354\n",
            "Epoch 3/500, Loss: 0.3903, Validation Loss: 0.3876, Validation Accuracy: 0.8354\n",
            "Epoch 4/500, Loss: 0.3866, Validation Loss: 0.3795, Validation Accuracy: 0.8391\n",
            "Epoch 5/500, Loss: 0.3782, Validation Loss: 0.3745, Validation Accuracy: 0.8406\n",
            "Epoch 6/500, Loss: 0.3682, Validation Loss: 0.3860, Validation Accuracy: 0.8354\n",
            "Epoch 7/500, Loss: 0.3667, Validation Loss: 0.3790, Validation Accuracy: 0.8354\n",
            "Epoch 8/500, Loss: 0.3576, Validation Loss: 0.3856, Validation Accuracy: 0.8372\n",
            "Epoch 9/500, Loss: 0.3555, Validation Loss: 0.3753, Validation Accuracy: 0.8437\n",
            "Epoch 10/500, Loss: 0.3568, Validation Loss: 0.3658, Validation Accuracy: 0.8442\n",
            "Epoch 11/500, Loss: 0.3516, Validation Loss: 0.3531, Validation Accuracy: 0.8539\n",
            "Epoch 12/500, Loss: 0.3496, Validation Loss: 0.3627, Validation Accuracy: 0.8500\n",
            "Epoch 13/500, Loss: 0.3477, Validation Loss: 0.3964, Validation Accuracy: 0.8359\n",
            "Epoch 14/500, Loss: 0.3517, Validation Loss: 0.3659, Validation Accuracy: 0.8488\n",
            "Epoch 15/500, Loss: 0.3469, Validation Loss: 0.3601, Validation Accuracy: 0.8519\n",
            "Epoch 16/500, Loss: 0.3450, Validation Loss: 0.3489, Validation Accuracy: 0.8592\n",
            "Epoch 17/500, Loss: 0.3415, Validation Loss: 0.3574, Validation Accuracy: 0.8537\n",
            "Epoch 18/500, Loss: 0.3411, Validation Loss: 0.3517, Validation Accuracy: 0.8532\n",
            "Epoch 19/500, Loss: 0.3397, Validation Loss: 0.3819, Validation Accuracy: 0.8439\n",
            "Epoch 20/500, Loss: 0.3405, Validation Loss: 0.3527, Validation Accuracy: 0.8570\n",
            "Epoch 21/500, Loss: 0.3366, Validation Loss: 0.3517, Validation Accuracy: 0.8587\n",
            "Epoch 22/500, Loss: 0.3375, Validation Loss: 0.3573, Validation Accuracy: 0.8541\n",
            "Epoch 23/500, Loss: 0.3381, Validation Loss: 0.3494, Validation Accuracy: 0.8617\n",
            "Epoch 24/500, Loss: 0.3385, Validation Loss: 0.3542, Validation Accuracy: 0.8539\n",
            "Epoch 25/500, Loss: 0.3341, Validation Loss: 0.3534, Validation Accuracy: 0.8588\n",
            "Epoch 26/500, Loss: 0.3375, Validation Loss: 0.3547, Validation Accuracy: 0.8534\n",
            "Epoch 27/500, Loss: 0.3344, Validation Loss: 0.3498, Validation Accuracy: 0.8571\n",
            "Epoch 28/500, Loss: 0.3362, Validation Loss: 0.3476, Validation Accuracy: 0.8577\n",
            "Epoch 29/500, Loss: 0.3317, Validation Loss: 0.3558, Validation Accuracy: 0.8539\n",
            "Epoch 30/500, Loss: 0.3352, Validation Loss: 0.3516, Validation Accuracy: 0.8556\n",
            "Epoch 31/500, Loss: 0.3314, Validation Loss: 0.3510, Validation Accuracy: 0.8590\n",
            "Epoch 32/500, Loss: 0.3300, Validation Loss: 0.3453, Validation Accuracy: 0.8602\n",
            "Epoch 33/500, Loss: 0.3316, Validation Loss: 0.3504, Validation Accuracy: 0.8568\n",
            "Epoch 34/500, Loss: 0.3275, Validation Loss: 0.3593, Validation Accuracy: 0.8554\n",
            "Epoch 35/500, Loss: 0.3301, Validation Loss: 0.3675, Validation Accuracy: 0.8512\n",
            "Epoch 36/500, Loss: 0.3274, Validation Loss: 0.3434, Validation Accuracy: 0.8600\n",
            "Epoch 37/500, Loss: 0.3257, Validation Loss: 0.3545, Validation Accuracy: 0.8548\n",
            "Epoch 38/500, Loss: 0.3258, Validation Loss: 0.3453, Validation Accuracy: 0.8582\n",
            "Epoch 39/500, Loss: 0.3262, Validation Loss: 0.3512, Validation Accuracy: 0.8558\n",
            "Epoch 40/500, Loss: 0.3276, Validation Loss: 0.3471, Validation Accuracy: 0.8580\n",
            "Epoch 41/500, Loss: 0.3221, Validation Loss: 0.3475, Validation Accuracy: 0.8565\n",
            "Epoch 42/500, Loss: 0.3219, Validation Loss: 0.3454, Validation Accuracy: 0.8605\n",
            "Epoch 43/500, Loss: 0.3211, Validation Loss: 0.3424, Validation Accuracy: 0.8607\n",
            "Epoch 44/500, Loss: 0.3163, Validation Loss: 0.3392, Validation Accuracy: 0.8614\n",
            "Epoch 45/500, Loss: 0.3188, Validation Loss: 0.3455, Validation Accuracy: 0.8597\n",
            "Epoch 46/500, Loss: 0.3187, Validation Loss: 0.3502, Validation Accuracy: 0.8563\n",
            "Epoch 47/500, Loss: 0.3234, Validation Loss: 0.3547, Validation Accuracy: 0.8595\n",
            "Epoch 48/500, Loss: 0.3204, Validation Loss: 0.3602, Validation Accuracy: 0.8534\n",
            "Epoch 49/500, Loss: 0.3163, Validation Loss: 0.3600, Validation Accuracy: 0.8577\n",
            "Epoch 50/500, Loss: 0.3187, Validation Loss: 0.3488, Validation Accuracy: 0.8566\n",
            "Epoch 51/500, Loss: 0.3130, Validation Loss: 0.3422, Validation Accuracy: 0.8604\n",
            "Epoch 52/500, Loss: 0.3150, Validation Loss: 0.3535, Validation Accuracy: 0.8595\n",
            "Epoch 53/500, Loss: 0.3155, Validation Loss: 0.3466, Validation Accuracy: 0.8600\n",
            "Epoch 54/500, Loss: 0.3130, Validation Loss: 0.3462, Validation Accuracy: 0.8619\n",
            "Epoch 55/500, Loss: 0.3153, Validation Loss: 0.3553, Validation Accuracy: 0.8587\n",
            "Epoch 56/500, Loss: 0.3179, Validation Loss: 0.3601, Validation Accuracy: 0.8595\n",
            "Epoch 57/500, Loss: 0.3182, Validation Loss: 0.3672, Validation Accuracy: 0.8549\n",
            "Epoch 58/500, Loss: 0.3127, Validation Loss: 0.3459, Validation Accuracy: 0.8602\n",
            "Epoch 59/500, Loss: 0.3089, Validation Loss: 0.3690, Validation Accuracy: 0.8546\n",
            "Epoch 60/500, Loss: 0.3103, Validation Loss: 0.3435, Validation Accuracy: 0.8588\n",
            "Epoch 61/500, Loss: 0.3097, Validation Loss: 0.3525, Validation Accuracy: 0.8616\n",
            "Epoch 62/500, Loss: 0.3104, Validation Loss: 0.3580, Validation Accuracy: 0.8571\n",
            "Epoch 63/500, Loss: 0.3044, Validation Loss: 0.3485, Validation Accuracy: 0.8619\n",
            "Epoch 64/500, Loss: 0.3032, Validation Loss: 0.3433, Validation Accuracy: 0.8621\n",
            "Epoch 65/500, Loss: 0.3104, Validation Loss: 0.3517, Validation Accuracy: 0.8587\n",
            "Epoch 66/500, Loss: 0.3112, Validation Loss: 0.3509, Validation Accuracy: 0.8568\n",
            "Epoch 67/500, Loss: 0.3067, Validation Loss: 0.3505, Validation Accuracy: 0.8604\n",
            "Epoch 68/500, Loss: 0.3086, Validation Loss: 0.3463, Validation Accuracy: 0.8588\n",
            "Epoch 69/500, Loss: 0.3059, Validation Loss: 0.3508, Validation Accuracy: 0.8578\n",
            "Epoch 70/500, Loss: 0.3048, Validation Loss: 0.3522, Validation Accuracy: 0.8561\n",
            "Epoch 71/500, Loss: 0.3026, Validation Loss: 0.3672, Validation Accuracy: 0.8580\n",
            "Epoch 72/500, Loss: 0.3071, Validation Loss: 0.3617, Validation Accuracy: 0.8571\n",
            "Epoch 73/500, Loss: 0.3067, Validation Loss: 0.3482, Validation Accuracy: 0.8612\n",
            "Epoch 74/500, Loss: 0.3051, Validation Loss: 0.3433, Validation Accuracy: 0.8617\n",
            "Epoch 75/500, Loss: 0.3016, Validation Loss: 0.3462, Validation Accuracy: 0.8607\n",
            "Epoch 76/500, Loss: 0.2967, Validation Loss: 0.3431, Validation Accuracy: 0.8634\n",
            "Epoch 77/500, Loss: 0.3006, Validation Loss: 0.3516, Validation Accuracy: 0.8612\n",
            "Epoch 78/500, Loss: 0.2951, Validation Loss: 0.3414, Validation Accuracy: 0.8604\n",
            "Epoch 79/500, Loss: 0.2969, Validation Loss: 0.3496, Validation Accuracy: 0.8634\n",
            "Epoch 80/500, Loss: 0.2960, Validation Loss: 0.3509, Validation Accuracy: 0.8585\n",
            "Epoch 81/500, Loss: 0.2928, Validation Loss: 0.3604, Validation Accuracy: 0.8566\n",
            "Epoch 82/500, Loss: 0.2972, Validation Loss: 0.3496, Validation Accuracy: 0.8587\n",
            "Epoch 83/500, Loss: 0.2989, Validation Loss: 0.3495, Validation Accuracy: 0.8560\n",
            "Epoch 84/500, Loss: 0.2979, Validation Loss: 0.3712, Validation Accuracy: 0.8510\n",
            "Epoch 85/500, Loss: 0.2902, Validation Loss: 0.3518, Validation Accuracy: 0.8621\n",
            "Epoch 86/500, Loss: 0.2943, Validation Loss: 0.3562, Validation Accuracy: 0.8631\n",
            "Epoch 87/500, Loss: 0.2964, Validation Loss: 0.3606, Validation Accuracy: 0.8554\n",
            "Epoch 88/500, Loss: 0.2890, Validation Loss: 0.3445, Validation Accuracy: 0.8609\n",
            "Epoch 89/500, Loss: 0.2917, Validation Loss: 0.3426, Validation Accuracy: 0.8609\n",
            "Epoch 90/500, Loss: 0.2951, Validation Loss: 0.3396, Validation Accuracy: 0.8672\n",
            "Epoch 91/500, Loss: 0.2942, Validation Loss: 0.3561, Validation Accuracy: 0.8641\n",
            "Epoch 92/500, Loss: 0.2908, Validation Loss: 0.3574, Validation Accuracy: 0.8594\n",
            "Epoch 93/500, Loss: 0.2889, Validation Loss: 0.3484, Validation Accuracy: 0.8566\n",
            "Epoch 94/500, Loss: 0.2852, Validation Loss: 0.3492, Validation Accuracy: 0.8594\n",
            "Epoch 95/500, Loss: 0.2843, Validation Loss: 0.3546, Validation Accuracy: 0.8587\n",
            "Epoch 96/500, Loss: 0.2884, Validation Loss: 0.3531, Validation Accuracy: 0.8619\n",
            "Epoch 97/500, Loss: 0.2841, Validation Loss: 0.3437, Validation Accuracy: 0.8600\n",
            "Epoch 98/500, Loss: 0.2806, Validation Loss: 0.3411, Validation Accuracy: 0.8617\n",
            "Epoch 99/500, Loss: 0.2816, Validation Loss: 0.3527, Validation Accuracy: 0.8631\n",
            "Epoch 100/500, Loss: 0.2774, Validation Loss: 0.3451, Validation Accuracy: 0.8617\n",
            "Epoch 101/500, Loss: 0.2830, Validation Loss: 0.3640, Validation Accuracy: 0.8549\n",
            "Epoch 102/500, Loss: 0.2879, Validation Loss: 0.3454, Validation Accuracy: 0.8636\n",
            "Epoch 103/500, Loss: 0.2831, Validation Loss: 0.3406, Validation Accuracy: 0.8600\n",
            "Epoch 104/500, Loss: 0.2800, Validation Loss: 0.3604, Validation Accuracy: 0.8539\n",
            "Epoch 105/500, Loss: 0.2873, Validation Loss: 0.3558, Validation Accuracy: 0.8604\n",
            "Epoch 106/500, Loss: 0.2867, Validation Loss: 0.3497, Validation Accuracy: 0.8648\n",
            "Epoch 107/500, Loss: 0.2836, Validation Loss: 0.3557, Validation Accuracy: 0.8587\n",
            "Epoch 108/500, Loss: 0.2749, Validation Loss: 0.3473, Validation Accuracy: 0.8636\n",
            "Epoch 109/500, Loss: 0.2760, Validation Loss: 0.3483, Validation Accuracy: 0.8616\n",
            "Epoch 110/500, Loss: 0.2794, Validation Loss: 0.3409, Validation Accuracy: 0.8628\n",
            "Epoch 111/500, Loss: 0.2816, Validation Loss: 0.3624, Validation Accuracy: 0.8495\n",
            "Epoch 112/500, Loss: 0.2794, Validation Loss: 0.3639, Validation Accuracy: 0.8549\n",
            "Epoch 113/500, Loss: 0.2741, Validation Loss: 0.3517, Validation Accuracy: 0.8592\n",
            "Epoch 114/500, Loss: 0.2796, Validation Loss: 0.3637, Validation Accuracy: 0.8607\n",
            "Epoch 115/500, Loss: 0.2746, Validation Loss: 0.3735, Validation Accuracy: 0.8587\n",
            "Epoch 116/500, Loss: 0.2726, Validation Loss: 0.3719, Validation Accuracy: 0.8544\n",
            "Epoch 117/500, Loss: 0.2671, Validation Loss: 0.3554, Validation Accuracy: 0.8524\n",
            "Epoch 118/500, Loss: 0.2672, Validation Loss: 0.3568, Validation Accuracy: 0.8549\n",
            "Epoch 119/500, Loss: 0.2660, Validation Loss: 0.3426, Validation Accuracy: 0.8611\n",
            "Epoch 120/500, Loss: 0.2673, Validation Loss: 0.3447, Validation Accuracy: 0.8636\n",
            "Epoch 121/500, Loss: 0.2689, Validation Loss: 0.3513, Validation Accuracy: 0.8628\n",
            "Epoch 122/500, Loss: 0.2624, Validation Loss: 0.3442, Validation Accuracy: 0.8571\n",
            "Epoch 123/500, Loss: 0.2666, Validation Loss: 0.3458, Validation Accuracy: 0.8624\n",
            "Epoch 124/500, Loss: 0.2617, Validation Loss: 0.3613, Validation Accuracy: 0.8607\n",
            "Epoch 125/500, Loss: 0.2609, Validation Loss: 0.3508, Validation Accuracy: 0.8607\n",
            "Epoch 126/500, Loss: 0.2594, Validation Loss: 0.3371, Validation Accuracy: 0.8619\n",
            "Epoch 127/500, Loss: 0.2594, Validation Loss: 0.3413, Validation Accuracy: 0.8631\n",
            "Epoch 128/500, Loss: 0.2617, Validation Loss: 0.3460, Validation Accuracy: 0.8628\n",
            "Epoch 129/500, Loss: 0.2581, Validation Loss: 0.3476, Validation Accuracy: 0.8628\n",
            "Epoch 130/500, Loss: 0.2570, Validation Loss: 0.3735, Validation Accuracy: 0.8551\n",
            "Epoch 131/500, Loss: 0.2586, Validation Loss: 0.3553, Validation Accuracy: 0.8565\n",
            "Epoch 132/500, Loss: 0.2577, Validation Loss: 0.3564, Validation Accuracy: 0.8588\n",
            "Epoch 133/500, Loss: 0.2551, Validation Loss: 0.3388, Validation Accuracy: 0.8656\n",
            "Epoch 134/500, Loss: 0.2578, Validation Loss: 0.3634, Validation Accuracy: 0.8633\n",
            "Epoch 135/500, Loss: 0.2585, Validation Loss: 0.3499, Validation Accuracy: 0.8605\n",
            "Epoch 136/500, Loss: 0.2573, Validation Loss: 0.3599, Validation Accuracy: 0.8563\n",
            "Epoch 137/500, Loss: 0.2549, Validation Loss: 0.3563, Validation Accuracy: 0.8605\n",
            "Epoch 138/500, Loss: 0.2547, Validation Loss: 0.3500, Validation Accuracy: 0.8609\n",
            "Epoch 139/500, Loss: 0.2582, Validation Loss: 0.3509, Validation Accuracy: 0.8600\n",
            "Epoch 140/500, Loss: 0.2581, Validation Loss: 0.3543, Validation Accuracy: 0.8595\n",
            "Epoch 141/500, Loss: 0.2546, Validation Loss: 0.3608, Validation Accuracy: 0.8595\n",
            "Epoch 142/500, Loss: 0.2601, Validation Loss: 0.3480, Validation Accuracy: 0.8605\n",
            "Epoch 143/500, Loss: 0.2560, Validation Loss: 0.3494, Validation Accuracy: 0.8614\n",
            "Epoch 144/500, Loss: 0.2528, Validation Loss: 0.3526, Validation Accuracy: 0.8595\n",
            "Epoch 145/500, Loss: 0.2498, Validation Loss: 0.3516, Validation Accuracy: 0.8639\n",
            "Epoch 146/500, Loss: 0.2478, Validation Loss: 0.3386, Validation Accuracy: 0.8628\n",
            "Epoch 147/500, Loss: 0.2483, Validation Loss: 0.3427, Validation Accuracy: 0.8634\n",
            "Epoch 148/500, Loss: 0.2477, Validation Loss: 0.3400, Validation Accuracy: 0.8622\n",
            "Epoch 149/500, Loss: 0.2496, Validation Loss: 0.3394, Validation Accuracy: 0.8667\n",
            "Epoch 150/500, Loss: 0.2485, Validation Loss: 0.3490, Validation Accuracy: 0.8583\n",
            "Epoch 151/500, Loss: 0.2457, Validation Loss: 0.3466, Validation Accuracy: 0.8629\n",
            "Epoch 152/500, Loss: 0.2475, Validation Loss: 0.3535, Validation Accuracy: 0.8621\n",
            "Epoch 153/500, Loss: 0.2585, Validation Loss: 0.3558, Validation Accuracy: 0.8636\n",
            "Epoch 154/500, Loss: 0.2530, Validation Loss: 0.3631, Validation Accuracy: 0.8544\n",
            "Epoch 155/500, Loss: 0.2527, Validation Loss: 0.3622, Validation Accuracy: 0.8604\n",
            "Epoch 156/500, Loss: 0.2546, Validation Loss: 0.3530, Validation Accuracy: 0.8592\n",
            "Epoch 157/500, Loss: 0.2490, Validation Loss: 0.3610, Validation Accuracy: 0.8592\n",
            "Epoch 158/500, Loss: 0.2439, Validation Loss: 0.3498, Validation Accuracy: 0.8616\n",
            "Epoch 159/500, Loss: 0.2482, Validation Loss: 0.3789, Validation Accuracy: 0.8599\n",
            "Epoch 160/500, Loss: 0.2511, Validation Loss: 0.3409, Validation Accuracy: 0.8660\n",
            "Epoch 161/500, Loss: 0.2452, Validation Loss: 0.3574, Validation Accuracy: 0.8626\n",
            "Epoch 162/500, Loss: 0.2405, Validation Loss: 0.3551, Validation Accuracy: 0.8612\n",
            "Epoch 163/500, Loss: 0.2440, Validation Loss: 0.3472, Validation Accuracy: 0.8656\n",
            "Epoch 164/500, Loss: 0.2421, Validation Loss: 0.3447, Validation Accuracy: 0.8662\n",
            "Epoch 165/500, Loss: 0.2427, Validation Loss: 0.3611, Validation Accuracy: 0.8573\n",
            "Epoch 166/500, Loss: 0.2423, Validation Loss: 0.3548, Validation Accuracy: 0.8611\n",
            "Epoch 167/500, Loss: 0.2420, Validation Loss: 0.3482, Validation Accuracy: 0.8638\n",
            "Epoch 168/500, Loss: 0.2425, Validation Loss: 0.3463, Validation Accuracy: 0.8677\n",
            "Epoch 169/500, Loss: 0.2412, Validation Loss: 0.3627, Validation Accuracy: 0.8571\n",
            "Epoch 170/500, Loss: 0.2397, Validation Loss: 0.3547, Validation Accuracy: 0.8624\n",
            "Epoch 171/500, Loss: 0.2393, Validation Loss: 0.3556, Validation Accuracy: 0.8594\n",
            "Epoch 172/500, Loss: 0.2419, Validation Loss: 0.3357, Validation Accuracy: 0.8670\n",
            "Epoch 173/500, Loss: 0.2424, Validation Loss: 0.3503, Validation Accuracy: 0.8624\n",
            "Epoch 174/500, Loss: 0.2411, Validation Loss: 0.3690, Validation Accuracy: 0.8611\n",
            "Epoch 175/500, Loss: 0.2430, Validation Loss: 0.3529, Validation Accuracy: 0.8616\n",
            "Epoch 176/500, Loss: 0.2380, Validation Loss: 0.3558, Validation Accuracy: 0.8607\n",
            "Epoch 177/500, Loss: 0.2471, Validation Loss: 0.3432, Validation Accuracy: 0.8655\n",
            "Epoch 178/500, Loss: 0.2380, Validation Loss: 0.3606, Validation Accuracy: 0.8616\n",
            "Epoch 179/500, Loss: 0.2381, Validation Loss: 0.3741, Validation Accuracy: 0.8582\n",
            "Epoch 180/500, Loss: 0.2389, Validation Loss: 0.3584, Validation Accuracy: 0.8621\n",
            "Epoch 181/500, Loss: 0.2357, Validation Loss: 0.3577, Validation Accuracy: 0.8633\n",
            "Epoch 182/500, Loss: 0.2401, Validation Loss: 0.3472, Validation Accuracy: 0.8631\n",
            "Epoch 183/500, Loss: 0.2383, Validation Loss: 0.3577, Validation Accuracy: 0.8605\n",
            "Epoch 184/500, Loss: 0.2389, Validation Loss: 0.3556, Validation Accuracy: 0.8653\n",
            "Epoch 185/500, Loss: 0.2343, Validation Loss: 0.3526, Validation Accuracy: 0.8585\n",
            "Epoch 186/500, Loss: 0.2347, Validation Loss: 0.3605, Validation Accuracy: 0.8600\n",
            "Epoch 187/500, Loss: 0.2363, Validation Loss: 0.3567, Validation Accuracy: 0.8638\n",
            "Epoch 188/500, Loss: 0.2376, Validation Loss: 0.3647, Validation Accuracy: 0.8600\n",
            "Epoch 189/500, Loss: 0.2355, Validation Loss: 0.3421, Validation Accuracy: 0.8655\n",
            "Epoch 190/500, Loss: 0.2344, Validation Loss: 0.3466, Validation Accuracy: 0.8639\n",
            "Epoch 191/500, Loss: 0.2340, Validation Loss: 0.3574, Validation Accuracy: 0.8626\n",
            "Epoch 192/500, Loss: 0.2325, Validation Loss: 0.3610, Validation Accuracy: 0.8556\n",
            "Epoch 193/500, Loss: 0.2305, Validation Loss: 0.3554, Validation Accuracy: 0.8605\n",
            "Epoch 194/500, Loss: 0.2317, Validation Loss: 0.3535, Validation Accuracy: 0.8602\n",
            "Epoch 195/500, Loss: 0.2321, Validation Loss: 0.3464, Validation Accuracy: 0.8602\n",
            "Epoch 196/500, Loss: 0.2290, Validation Loss: 0.3506, Validation Accuracy: 0.8619\n",
            "Epoch 197/500, Loss: 0.2297, Validation Loss: 0.3484, Validation Accuracy: 0.8594\n",
            "Epoch 198/500, Loss: 0.2302, Validation Loss: 0.3592, Validation Accuracy: 0.8604\n",
            "Epoch 199/500, Loss: 0.2256, Validation Loss: 0.3434, Validation Accuracy: 0.8645\n",
            "Epoch 200/500, Loss: 0.2271, Validation Loss: 0.3548, Validation Accuracy: 0.8605\n",
            "Epoch 201/500, Loss: 0.2234, Validation Loss: 0.3466, Validation Accuracy: 0.8628\n",
            "Epoch 202/500, Loss: 0.2262, Validation Loss: 0.3623, Validation Accuracy: 0.8605\n",
            "Epoch 203/500, Loss: 0.2263, Validation Loss: 0.3661, Validation Accuracy: 0.8604\n",
            "Epoch 204/500, Loss: 0.2251, Validation Loss: 0.3674, Validation Accuracy: 0.8600\n",
            "Epoch 205/500, Loss: 0.2261, Validation Loss: 0.3603, Validation Accuracy: 0.8566\n",
            "Epoch 206/500, Loss: 0.2289, Validation Loss: 0.3703, Validation Accuracy: 0.8611\n",
            "Epoch 207/500, Loss: 0.2298, Validation Loss: 0.3629, Validation Accuracy: 0.8616\n",
            "Epoch 208/500, Loss: 0.2304, Validation Loss: 0.3529, Validation Accuracy: 0.8594\n",
            "Epoch 209/500, Loss: 0.2299, Validation Loss: 0.3559, Validation Accuracy: 0.8599\n",
            "Epoch 210/500, Loss: 0.2464, Validation Loss: 0.3953, Validation Accuracy: 0.8568\n",
            "Epoch 211/500, Loss: 0.2416, Validation Loss: 0.3805, Validation Accuracy: 0.8563\n",
            "Epoch 212/500, Loss: 0.2394, Validation Loss: 0.3756, Validation Accuracy: 0.8563\n",
            "Epoch 213/500, Loss: 0.2333, Validation Loss: 0.3674, Validation Accuracy: 0.8583\n",
            "Epoch 214/500, Loss: 0.2306, Validation Loss: 0.3595, Validation Accuracy: 0.8585\n",
            "Epoch 215/500, Loss: 0.2284, Validation Loss: 0.3632, Validation Accuracy: 0.8643\n",
            "Epoch 216/500, Loss: 0.2220, Validation Loss: 0.3623, Validation Accuracy: 0.8612\n",
            "Epoch 217/500, Loss: 0.2275, Validation Loss: 0.3623, Validation Accuracy: 0.8556\n",
            "Epoch 218/500, Loss: 0.2230, Validation Loss: 0.3619, Validation Accuracy: 0.8597\n",
            "Epoch 219/500, Loss: 0.2226, Validation Loss: 0.3661, Validation Accuracy: 0.8609\n",
            "Epoch 220/500, Loss: 0.2238, Validation Loss: 0.3637, Validation Accuracy: 0.8563\n",
            "Epoch 221/500, Loss: 0.2236, Validation Loss: 0.3564, Validation Accuracy: 0.8616\n",
            "Epoch 222/500, Loss: 0.2246, Validation Loss: 0.3677, Validation Accuracy: 0.8558\n",
            "Epoch 223/500, Loss: 0.2224, Validation Loss: 0.3696, Validation Accuracy: 0.8592\n",
            "Epoch 224/500, Loss: 0.2235, Validation Loss: 0.3776, Validation Accuracy: 0.8600\n",
            "Epoch 225/500, Loss: 0.2246, Validation Loss: 0.3794, Validation Accuracy: 0.8594\n",
            "Epoch 226/500, Loss: 0.2217, Validation Loss: 0.3561, Validation Accuracy: 0.8624\n",
            "Epoch 227/500, Loss: 0.2242, Validation Loss: 0.3792, Validation Accuracy: 0.8532\n",
            "Epoch 228/500, Loss: 0.2260, Validation Loss: 0.3689, Validation Accuracy: 0.8616\n",
            "Epoch 229/500, Loss: 0.2229, Validation Loss: 0.3624, Validation Accuracy: 0.8634\n",
            "Epoch 230/500, Loss: 0.2207, Validation Loss: 0.3729, Validation Accuracy: 0.8563\n",
            "Epoch 231/500, Loss: 0.2176, Validation Loss: 0.3636, Validation Accuracy: 0.8600\n",
            "Epoch 232/500, Loss: 0.2166, Validation Loss: 0.3554, Validation Accuracy: 0.8638\n",
            "Epoch 233/500, Loss: 0.2203, Validation Loss: 0.3587, Validation Accuracy: 0.8561\n",
            "Epoch 234/500, Loss: 0.2178, Validation Loss: 0.3654, Validation Accuracy: 0.8663\n",
            "Epoch 235/500, Loss: 0.2174, Validation Loss: 0.3636, Validation Accuracy: 0.8633\n",
            "Epoch 236/500, Loss: 0.2172, Validation Loss: 0.3464, Validation Accuracy: 0.8663\n",
            "Epoch 237/500, Loss: 0.2142, Validation Loss: 0.3616, Validation Accuracy: 0.8626\n",
            "Epoch 238/500, Loss: 0.2183, Validation Loss: 0.3611, Validation Accuracy: 0.8597\n",
            "Epoch 239/500, Loss: 0.2151, Validation Loss: 0.3528, Validation Accuracy: 0.8639\n",
            "Epoch 240/500, Loss: 0.2184, Validation Loss: 0.3473, Validation Accuracy: 0.8663\n",
            "Epoch 241/500, Loss: 0.2171, Validation Loss: 0.3715, Validation Accuracy: 0.8633\n",
            "Epoch 242/500, Loss: 0.2234, Validation Loss: 0.3631, Validation Accuracy: 0.8636\n",
            "Epoch 243/500, Loss: 0.2231, Validation Loss: 0.3721, Validation Accuracy: 0.8617\n",
            "Epoch 244/500, Loss: 0.2199, Validation Loss: 0.3565, Validation Accuracy: 0.8645\n",
            "Epoch 245/500, Loss: 0.2149, Validation Loss: 0.3687, Validation Accuracy: 0.8609\n",
            "Epoch 246/500, Loss: 0.2172, Validation Loss: 0.3877, Validation Accuracy: 0.8546\n",
            "Epoch 247/500, Loss: 0.2170, Validation Loss: 0.3825, Validation Accuracy: 0.8556\n",
            "Epoch 248/500, Loss: 0.2250, Validation Loss: 0.3814, Validation Accuracy: 0.8594\n",
            "Epoch 249/500, Loss: 0.2178, Validation Loss: 0.3756, Validation Accuracy: 0.8570\n",
            "Epoch 250/500, Loss: 0.2179, Validation Loss: 0.3733, Validation Accuracy: 0.8534\n",
            "Epoch 251/500, Loss: 0.2162, Validation Loss: 0.3710, Validation Accuracy: 0.8595\n",
            "Epoch 252/500, Loss: 0.2158, Validation Loss: 0.3629, Validation Accuracy: 0.8565\n",
            "Epoch 253/500, Loss: 0.2132, Validation Loss: 0.3723, Validation Accuracy: 0.8554\n",
            "Epoch 254/500, Loss: 0.2118, Validation Loss: 0.3687, Validation Accuracy: 0.8595\n",
            "Epoch 255/500, Loss: 0.2154, Validation Loss: 0.3626, Validation Accuracy: 0.8621\n",
            "Epoch 256/500, Loss: 0.2109, Validation Loss: 0.3591, Validation Accuracy: 0.8588\n",
            "Epoch 257/500, Loss: 0.2116, Validation Loss: 0.3762, Validation Accuracy: 0.8616\n",
            "Epoch 258/500, Loss: 0.2127, Validation Loss: 0.3749, Validation Accuracy: 0.8588\n",
            "Epoch 259/500, Loss: 0.2130, Validation Loss: 0.3813, Validation Accuracy: 0.8599\n",
            "Epoch 260/500, Loss: 0.2104, Validation Loss: 0.3802, Validation Accuracy: 0.8605\n",
            "Epoch 261/500, Loss: 0.2165, Validation Loss: 0.3717, Validation Accuracy: 0.8539\n",
            "Epoch 262/500, Loss: 0.2115, Validation Loss: 0.3825, Validation Accuracy: 0.8563\n",
            "Epoch 263/500, Loss: 0.2095, Validation Loss: 0.3763, Validation Accuracy: 0.8558\n",
            "Epoch 264/500, Loss: 0.2116, Validation Loss: 0.3833, Validation Accuracy: 0.8541\n",
            "Epoch 265/500, Loss: 0.2099, Validation Loss: 0.3648, Validation Accuracy: 0.8605\n",
            "Epoch 266/500, Loss: 0.2102, Validation Loss: 0.4149, Validation Accuracy: 0.8480\n",
            "Epoch 267/500, Loss: 0.2547, Validation Loss: 0.4769, Validation Accuracy: 0.8461\n",
            "Epoch 268/500, Loss: 0.2600, Validation Loss: 0.3745, Validation Accuracy: 0.8573\n",
            "Epoch 269/500, Loss: 0.2462, Validation Loss: 0.3781, Validation Accuracy: 0.8587\n",
            "Epoch 270/500, Loss: 0.2350, Validation Loss: 0.3771, Validation Accuracy: 0.8626\n",
            "Epoch 271/500, Loss: 0.2275, Validation Loss: 0.3664, Validation Accuracy: 0.8582\n",
            "Epoch 272/500, Loss: 0.2238, Validation Loss: 0.3561, Validation Accuracy: 0.8645\n",
            "Epoch 273/500, Loss: 0.2219, Validation Loss: 0.3518, Validation Accuracy: 0.8609\n",
            "Epoch 274/500, Loss: 0.2147, Validation Loss: 0.3803, Validation Accuracy: 0.8612\n",
            "Epoch 275/500, Loss: 0.2170, Validation Loss: 0.3614, Validation Accuracy: 0.8631\n",
            "Epoch 276/500, Loss: 0.2142, Validation Loss: 0.3553, Validation Accuracy: 0.8663\n",
            "Epoch 277/500, Loss: 0.2165, Validation Loss: 0.3583, Validation Accuracy: 0.8624\n",
            "Epoch 278/500, Loss: 0.2141, Validation Loss: 0.3753, Validation Accuracy: 0.8621\n",
            "Epoch 279/500, Loss: 0.2114, Validation Loss: 0.3586, Validation Accuracy: 0.8675\n",
            "Epoch 280/500, Loss: 0.2141, Validation Loss: 0.3777, Validation Accuracy: 0.8612\n",
            "Epoch 281/500, Loss: 0.2138, Validation Loss: 0.3754, Validation Accuracy: 0.8592\n",
            "Epoch 282/500, Loss: 0.2127, Validation Loss: 0.3832, Validation Accuracy: 0.8566\n",
            "Epoch 283/500, Loss: 0.2088, Validation Loss: 0.3611, Validation Accuracy: 0.8668\n",
            "Epoch 284/500, Loss: 0.2108, Validation Loss: 0.3661, Validation Accuracy: 0.8631\n",
            "Epoch 285/500, Loss: 0.2096, Validation Loss: 0.3765, Validation Accuracy: 0.8604\n",
            "Epoch 286/500, Loss: 0.2105, Validation Loss: 0.3827, Validation Accuracy: 0.8563\n",
            "Epoch 287/500, Loss: 0.2097, Validation Loss: 0.3872, Validation Accuracy: 0.8549\n",
            "Epoch 288/500, Loss: 0.2094, Validation Loss: 0.3837, Validation Accuracy: 0.8607\n",
            "Epoch 289/500, Loss: 0.2078, Validation Loss: 0.3704, Validation Accuracy: 0.8585\n",
            "Epoch 290/500, Loss: 0.2053, Validation Loss: 0.3753, Validation Accuracy: 0.8605\n",
            "Epoch 291/500, Loss: 0.2058, Validation Loss: 0.3807, Validation Accuracy: 0.8619\n",
            "Epoch 292/500, Loss: 0.2046, Validation Loss: 0.3748, Validation Accuracy: 0.8575\n",
            "Epoch 293/500, Loss: 0.2123, Validation Loss: 0.3719, Validation Accuracy: 0.8605\n",
            "Epoch 294/500, Loss: 0.2089, Validation Loss: 0.4255, Validation Accuracy: 0.8568\n",
            "Epoch 295/500, Loss: 0.2088, Validation Loss: 0.3832, Validation Accuracy: 0.8629\n",
            "Epoch 296/500, Loss: 0.2054, Validation Loss: 0.3716, Validation Accuracy: 0.8604\n",
            "Epoch 297/500, Loss: 0.2064, Validation Loss: 0.3662, Validation Accuracy: 0.8624\n",
            "Epoch 298/500, Loss: 0.2022, Validation Loss: 0.3672, Validation Accuracy: 0.8629\n",
            "Epoch 299/500, Loss: 0.2047, Validation Loss: 0.3805, Validation Accuracy: 0.8585\n",
            "Epoch 300/500, Loss: 0.2016, Validation Loss: 0.3802, Validation Accuracy: 0.8605\n",
            "Epoch 301/500, Loss: 0.2048, Validation Loss: 0.3827, Validation Accuracy: 0.8643\n",
            "Epoch 302/500, Loss: 0.2059, Validation Loss: 0.3827, Validation Accuracy: 0.8599\n",
            "Epoch 303/500, Loss: 0.2086, Validation Loss: 0.4006, Validation Accuracy: 0.8563\n",
            "Epoch 304/500, Loss: 0.2067, Validation Loss: 0.3889, Validation Accuracy: 0.8631\n",
            "Epoch 305/500, Loss: 0.2063, Validation Loss: 0.3883, Validation Accuracy: 0.8599\n",
            "Epoch 306/500, Loss: 0.2057, Validation Loss: 0.3890, Validation Accuracy: 0.8553\n",
            "Epoch 307/500, Loss: 0.2060, Validation Loss: 0.3795, Validation Accuracy: 0.8604\n",
            "Epoch 308/500, Loss: 0.2006, Validation Loss: 0.3623, Validation Accuracy: 0.8643\n",
            "Epoch 309/500, Loss: 0.2018, Validation Loss: 0.3715, Validation Accuracy: 0.8605\n",
            "Epoch 310/500, Loss: 0.2103, Validation Loss: 0.3948, Validation Accuracy: 0.8571\n",
            "Epoch 311/500, Loss: 0.2138, Validation Loss: 0.3995, Validation Accuracy: 0.8536\n",
            "Epoch 312/500, Loss: 0.2141, Validation Loss: 0.3826, Validation Accuracy: 0.8604\n",
            "Epoch 313/500, Loss: 0.2105, Validation Loss: 0.3830, Validation Accuracy: 0.8524\n",
            "Epoch 314/500, Loss: 0.2013, Validation Loss: 0.3996, Validation Accuracy: 0.8541\n",
            "Epoch 315/500, Loss: 0.2048, Validation Loss: 0.3862, Validation Accuracy: 0.8571\n",
            "Epoch 316/500, Loss: 0.2017, Validation Loss: 0.3961, Validation Accuracy: 0.8554\n",
            "Epoch 317/500, Loss: 0.2047, Validation Loss: 0.3854, Validation Accuracy: 0.8570\n",
            "Epoch 318/500, Loss: 0.2012, Validation Loss: 0.3795, Validation Accuracy: 0.8607\n",
            "Epoch 319/500, Loss: 0.2015, Validation Loss: 0.3836, Validation Accuracy: 0.8600\n",
            "Epoch 320/500, Loss: 0.2023, Validation Loss: 0.3687, Validation Accuracy: 0.8643\n",
            "Epoch 321/500, Loss: 0.1996, Validation Loss: 0.3940, Validation Accuracy: 0.8600\n",
            "Epoch 322/500, Loss: 0.2040, Validation Loss: 0.3907, Validation Accuracy: 0.8575\n",
            "Epoch 323/500, Loss: 0.2024, Validation Loss: 0.3866, Validation Accuracy: 0.8553\n",
            "Epoch 324/500, Loss: 0.2006, Validation Loss: 0.3743, Validation Accuracy: 0.8605\n",
            "Epoch 325/500, Loss: 0.2025, Validation Loss: 0.3874, Validation Accuracy: 0.8582\n",
            "Epoch 326/500, Loss: 0.2012, Validation Loss: 0.3818, Validation Accuracy: 0.8575\n",
            "Epoch 327/500, Loss: 0.2002, Validation Loss: 0.3798, Validation Accuracy: 0.8582\n",
            "Epoch 328/500, Loss: 0.1963, Validation Loss: 0.3638, Validation Accuracy: 0.8643\n",
            "Epoch 329/500, Loss: 0.1958, Validation Loss: 0.3806, Validation Accuracy: 0.8599\n",
            "Epoch 330/500, Loss: 0.1966, Validation Loss: 0.3687, Validation Accuracy: 0.8624\n",
            "Epoch 331/500, Loss: 0.1957, Validation Loss: 0.3736, Validation Accuracy: 0.8655\n",
            "Epoch 332/500, Loss: 0.1944, Validation Loss: 0.3784, Validation Accuracy: 0.8626\n",
            "Epoch 333/500, Loss: 0.1975, Validation Loss: 0.3746, Validation Accuracy: 0.8634\n",
            "Epoch 334/500, Loss: 0.1955, Validation Loss: 0.3842, Validation Accuracy: 0.8580\n",
            "Epoch 335/500, Loss: 0.1949, Validation Loss: 0.3825, Validation Accuracy: 0.8587\n",
            "Epoch 336/500, Loss: 0.1979, Validation Loss: 0.3738, Validation Accuracy: 0.8612\n",
            "Epoch 337/500, Loss: 0.1962, Validation Loss: 0.3921, Validation Accuracy: 0.8575\n",
            "Epoch 338/500, Loss: 0.2045, Validation Loss: 0.4139, Validation Accuracy: 0.8570\n",
            "Epoch 339/500, Loss: 0.2034, Validation Loss: 0.4447, Validation Accuracy: 0.8474\n",
            "Epoch 340/500, Loss: 0.2053, Validation Loss: 0.3796, Validation Accuracy: 0.8639\n",
            "Epoch 341/500, Loss: 0.2042, Validation Loss: 0.3755, Validation Accuracy: 0.8639\n",
            "Epoch 342/500, Loss: 0.1987, Validation Loss: 0.3565, Validation Accuracy: 0.8651\n",
            "Epoch 343/500, Loss: 0.1985, Validation Loss: 0.3769, Validation Accuracy: 0.8616\n",
            "Epoch 344/500, Loss: 0.1998, Validation Loss: 0.3756, Validation Accuracy: 0.8631\n",
            "Epoch 345/500, Loss: 0.1969, Validation Loss: 0.3946, Validation Accuracy: 0.8597\n",
            "Epoch 346/500, Loss: 0.2034, Validation Loss: 0.3643, Validation Accuracy: 0.8682\n",
            "Epoch 347/500, Loss: 0.1945, Validation Loss: 0.3737, Validation Accuracy: 0.8624\n",
            "Epoch 348/500, Loss: 0.1951, Validation Loss: 0.3717, Validation Accuracy: 0.8607\n",
            "Epoch 349/500, Loss: 0.1947, Validation Loss: 0.3810, Validation Accuracy: 0.8616\n",
            "Epoch 350/500, Loss: 0.1999, Validation Loss: 0.4015, Validation Accuracy: 0.8653\n",
            "Epoch 351/500, Loss: 0.1965, Validation Loss: 0.3869, Validation Accuracy: 0.8597\n",
            "Epoch 352/500, Loss: 0.1974, Validation Loss: 0.4053, Validation Accuracy: 0.8604\n",
            "Epoch 353/500, Loss: 0.1980, Validation Loss: 0.3900, Validation Accuracy: 0.8575\n",
            "Epoch 354/500, Loss: 0.1966, Validation Loss: 0.3854, Validation Accuracy: 0.8607\n",
            "Epoch 355/500, Loss: 0.1915, Validation Loss: 0.3892, Validation Accuracy: 0.8578\n",
            "Epoch 356/500, Loss: 0.1944, Validation Loss: 0.3885, Validation Accuracy: 0.8629\n",
            "Epoch 357/500, Loss: 0.1925, Validation Loss: 0.3739, Validation Accuracy: 0.8621\n",
            "Epoch 358/500, Loss: 0.1927, Validation Loss: 0.3983, Validation Accuracy: 0.8612\n",
            "Epoch 359/500, Loss: 0.1955, Validation Loss: 0.3948, Validation Accuracy: 0.8631\n",
            "Epoch 360/500, Loss: 0.1899, Validation Loss: 0.3930, Validation Accuracy: 0.8612\n",
            "Epoch 361/500, Loss: 0.1925, Validation Loss: 0.3883, Validation Accuracy: 0.8621\n",
            "Epoch 362/500, Loss: 0.1876, Validation Loss: 0.3878, Validation Accuracy: 0.8628\n",
            "Epoch 363/500, Loss: 0.1909, Validation Loss: 0.3835, Validation Accuracy: 0.8639\n",
            "Epoch 364/500, Loss: 0.1905, Validation Loss: 0.3802, Validation Accuracy: 0.8648\n",
            "Epoch 365/500, Loss: 0.1895, Validation Loss: 0.3884, Validation Accuracy: 0.8651\n",
            "Epoch 366/500, Loss: 0.1950, Validation Loss: 0.3968, Validation Accuracy: 0.8622\n",
            "Epoch 367/500, Loss: 0.1931, Validation Loss: 0.3980, Validation Accuracy: 0.8648\n",
            "Epoch 368/500, Loss: 0.1902, Validation Loss: 0.3934, Validation Accuracy: 0.8599\n",
            "Epoch 369/500, Loss: 0.1909, Validation Loss: 0.3885, Validation Accuracy: 0.8609\n",
            "Epoch 370/500, Loss: 0.1932, Validation Loss: 0.3979, Validation Accuracy: 0.8575\n",
            "Epoch 371/500, Loss: 0.1916, Validation Loss: 0.3905, Validation Accuracy: 0.8580\n",
            "Epoch 372/500, Loss: 0.1882, Validation Loss: 0.3898, Validation Accuracy: 0.8599\n",
            "Epoch 373/500, Loss: 0.1934, Validation Loss: 0.3807, Validation Accuracy: 0.8617\n",
            "Epoch 374/500, Loss: 0.1896, Validation Loss: 0.3884, Validation Accuracy: 0.8626\n",
            "Epoch 375/500, Loss: 0.1890, Validation Loss: 0.3888, Validation Accuracy: 0.8609\n",
            "Epoch 376/500, Loss: 0.1908, Validation Loss: 0.3949, Validation Accuracy: 0.8582\n",
            "Epoch 377/500, Loss: 0.1893, Validation Loss: 0.3847, Validation Accuracy: 0.8588\n",
            "Epoch 378/500, Loss: 0.1956, Validation Loss: 0.3774, Validation Accuracy: 0.8626\n",
            "Epoch 379/500, Loss: 0.1966, Validation Loss: 0.4158, Validation Accuracy: 0.8544\n",
            "Epoch 380/500, Loss: 0.2033, Validation Loss: 0.4206, Validation Accuracy: 0.8577\n",
            "Epoch 381/500, Loss: 0.1987, Validation Loss: 0.4002, Validation Accuracy: 0.8594\n",
            "Epoch 382/500, Loss: 0.1969, Validation Loss: 0.3768, Validation Accuracy: 0.8605\n",
            "Epoch 383/500, Loss: 0.1977, Validation Loss: 0.4002, Validation Accuracy: 0.8607\n",
            "Epoch 384/500, Loss: 0.1970, Validation Loss: 0.3779, Validation Accuracy: 0.8611\n",
            "Epoch 385/500, Loss: 0.1962, Validation Loss: 0.3738, Validation Accuracy: 0.8631\n",
            "Epoch 386/500, Loss: 0.1956, Validation Loss: 0.3743, Validation Accuracy: 0.8648\n",
            "Epoch 387/500, Loss: 0.1942, Validation Loss: 0.3950, Validation Accuracy: 0.8583\n",
            "Epoch 388/500, Loss: 0.1927, Validation Loss: 0.3885, Validation Accuracy: 0.8599\n",
            "Epoch 389/500, Loss: 0.1909, Validation Loss: 0.3947, Validation Accuracy: 0.8570\n",
            "Epoch 390/500, Loss: 0.1897, Validation Loss: 0.3897, Validation Accuracy: 0.8609\n",
            "Epoch 391/500, Loss: 0.1885, Validation Loss: 0.3811, Validation Accuracy: 0.8633\n",
            "Epoch 392/500, Loss: 0.1876, Validation Loss: 0.3950, Validation Accuracy: 0.8597\n",
            "Epoch 393/500, Loss: 0.1895, Validation Loss: 0.4002, Validation Accuracy: 0.8653\n",
            "Epoch 394/500, Loss: 0.1899, Validation Loss: 0.3974, Validation Accuracy: 0.8621\n",
            "Epoch 395/500, Loss: 0.1859, Validation Loss: 0.3849, Validation Accuracy: 0.8651\n",
            "Epoch 396/500, Loss: 0.1856, Validation Loss: 0.3974, Validation Accuracy: 0.8587\n",
            "Epoch 397/500, Loss: 0.1880, Validation Loss: 0.4049, Validation Accuracy: 0.8617\n",
            "Epoch 398/500, Loss: 0.1900, Validation Loss: 0.3858, Validation Accuracy: 0.8660\n",
            "Epoch 399/500, Loss: 0.1882, Validation Loss: 0.3892, Validation Accuracy: 0.8628\n",
            "Epoch 400/500, Loss: 0.1849, Validation Loss: 0.3951, Validation Accuracy: 0.8609\n",
            "Epoch 401/500, Loss: 0.1907, Validation Loss: 0.3933, Validation Accuracy: 0.8663\n",
            "Epoch 402/500, Loss: 0.1849, Validation Loss: 0.3775, Validation Accuracy: 0.8672\n",
            "Epoch 403/500, Loss: 0.1857, Validation Loss: 0.3766, Validation Accuracy: 0.8643\n",
            "Epoch 404/500, Loss: 0.1922, Validation Loss: 0.3824, Validation Accuracy: 0.8611\n",
            "Epoch 405/500, Loss: 0.1838, Validation Loss: 0.3951, Validation Accuracy: 0.8611\n",
            "Epoch 406/500, Loss: 0.1850, Validation Loss: 0.4059, Validation Accuracy: 0.8590\n",
            "Epoch 407/500, Loss: 0.1860, Validation Loss: 0.4110, Validation Accuracy: 0.8570\n",
            "Epoch 408/500, Loss: 0.1863, Validation Loss: 0.4078, Validation Accuracy: 0.8602\n",
            "Epoch 409/500, Loss: 0.1868, Validation Loss: 0.3876, Validation Accuracy: 0.8592\n",
            "Epoch 410/500, Loss: 0.1882, Validation Loss: 0.3933, Validation Accuracy: 0.8629\n",
            "Epoch 411/500, Loss: 0.1841, Validation Loss: 0.3955, Validation Accuracy: 0.8605\n",
            "Epoch 412/500, Loss: 0.1834, Validation Loss: 0.3871, Validation Accuracy: 0.8597\n",
            "Epoch 413/500, Loss: 0.1852, Validation Loss: 0.4167, Validation Accuracy: 0.8543\n",
            "Epoch 414/500, Loss: 0.1821, Validation Loss: 0.3992, Validation Accuracy: 0.8568\n",
            "Epoch 415/500, Loss: 0.1842, Validation Loss: 0.4001, Validation Accuracy: 0.8554\n",
            "Epoch 416/500, Loss: 0.1883, Validation Loss: 0.3923, Validation Accuracy: 0.8646\n",
            "Epoch 417/500, Loss: 0.1945, Validation Loss: 0.4004, Validation Accuracy: 0.8556\n",
            "Epoch 418/500, Loss: 0.1894, Validation Loss: 0.4093, Validation Accuracy: 0.8549\n",
            "Epoch 419/500, Loss: 0.1858, Validation Loss: 0.4159, Validation Accuracy: 0.8522\n",
            "Epoch 420/500, Loss: 0.1815, Validation Loss: 0.4151, Validation Accuracy: 0.8546\n",
            "Epoch 421/500, Loss: 0.1825, Validation Loss: 0.4060, Validation Accuracy: 0.8568\n",
            "Epoch 422/500, Loss: 0.1910, Validation Loss: 0.3975, Validation Accuracy: 0.8604\n",
            "Epoch 423/500, Loss: 0.1855, Validation Loss: 0.4159, Validation Accuracy: 0.8619\n",
            "Epoch 424/500, Loss: 0.1853, Validation Loss: 0.4141, Validation Accuracy: 0.8595\n",
            "Epoch 425/500, Loss: 0.1845, Validation Loss: 0.4110, Validation Accuracy: 0.8587\n",
            "Epoch 426/500, Loss: 0.1857, Validation Loss: 0.4328, Validation Accuracy: 0.8577\n",
            "Epoch 427/500, Loss: 0.1833, Validation Loss: 0.4286, Validation Accuracy: 0.8565\n",
            "Epoch 428/500, Loss: 0.1864, Validation Loss: 0.4192, Validation Accuracy: 0.8600\n",
            "Epoch 429/500, Loss: 0.1841, Validation Loss: 0.3976, Validation Accuracy: 0.8643\n",
            "Epoch 430/500, Loss: 0.1833, Validation Loss: 0.4085, Validation Accuracy: 0.8616\n",
            "Epoch 431/500, Loss: 0.2020, Validation Loss: 0.4166, Validation Accuracy: 0.8587\n",
            "Epoch 432/500, Loss: 0.2024, Validation Loss: 0.4124, Validation Accuracy: 0.8590\n",
            "Epoch 433/500, Loss: 0.2014, Validation Loss: 0.3961, Validation Accuracy: 0.8614\n",
            "Epoch 434/500, Loss: 0.1948, Validation Loss: 0.4101, Validation Accuracy: 0.8660\n",
            "Epoch 435/500, Loss: 0.1920, Validation Loss: 0.4111, Validation Accuracy: 0.8605\n",
            "Epoch 436/500, Loss: 0.1916, Validation Loss: 0.4368, Validation Accuracy: 0.8553\n",
            "Epoch 437/500, Loss: 0.1894, Validation Loss: 0.3984, Validation Accuracy: 0.8641\n",
            "Epoch 438/500, Loss: 0.1887, Validation Loss: 0.3986, Validation Accuracy: 0.8665\n",
            "Epoch 439/500, Loss: 0.1864, Validation Loss: 0.4064, Validation Accuracy: 0.8650\n",
            "Epoch 440/500, Loss: 0.1837, Validation Loss: 0.4070, Validation Accuracy: 0.8655\n",
            "Epoch 441/500, Loss: 0.1860, Validation Loss: 0.4053, Validation Accuracy: 0.8622\n",
            "Epoch 442/500, Loss: 0.1916, Validation Loss: 0.4055, Validation Accuracy: 0.8611\n",
            "Epoch 443/500, Loss: 0.1860, Validation Loss: 0.4080, Validation Accuracy: 0.8575\n",
            "Epoch 444/500, Loss: 0.1881, Validation Loss: 0.4058, Validation Accuracy: 0.8568\n",
            "Epoch 445/500, Loss: 0.1888, Validation Loss: 0.3950, Validation Accuracy: 0.8594\n",
            "Epoch 446/500, Loss: 0.1859, Validation Loss: 0.4036, Validation Accuracy: 0.8602\n",
            "Epoch 447/500, Loss: 0.1811, Validation Loss: 0.4146, Validation Accuracy: 0.8582\n",
            "Epoch 448/500, Loss: 0.1784, Validation Loss: 0.4196, Validation Accuracy: 0.8549\n",
            "Epoch 449/500, Loss: 0.1813, Validation Loss: 0.4069, Validation Accuracy: 0.8597\n",
            "Epoch 450/500, Loss: 0.1834, Validation Loss: 0.4102, Validation Accuracy: 0.8578\n",
            "Epoch 451/500, Loss: 0.1837, Validation Loss: 0.4067, Validation Accuracy: 0.8617\n",
            "Epoch 452/500, Loss: 0.1791, Validation Loss: 0.4151, Validation Accuracy: 0.8614\n",
            "Epoch 453/500, Loss: 0.1830, Validation Loss: 0.4011, Validation Accuracy: 0.8646\n",
            "Epoch 454/500, Loss: 0.1794, Validation Loss: 0.3894, Validation Accuracy: 0.8668\n",
            "Epoch 455/500, Loss: 0.1766, Validation Loss: 0.4008, Validation Accuracy: 0.8590\n",
            "Epoch 456/500, Loss: 0.1802, Validation Loss: 0.3990, Validation Accuracy: 0.8616\n",
            "Epoch 457/500, Loss: 0.1786, Validation Loss: 0.4091, Validation Accuracy: 0.8577\n",
            "Epoch 458/500, Loss: 0.1787, Validation Loss: 0.4192, Validation Accuracy: 0.8590\n",
            "Epoch 459/500, Loss: 0.1804, Validation Loss: 0.4158, Validation Accuracy: 0.8631\n",
            "Epoch 460/500, Loss: 0.1795, Validation Loss: 0.3968, Validation Accuracy: 0.8621\n",
            "Epoch 461/500, Loss: 0.1774, Validation Loss: 0.4111, Validation Accuracy: 0.8655\n",
            "Epoch 462/500, Loss: 0.1756, Validation Loss: 0.4261, Validation Accuracy: 0.8619\n",
            "Epoch 463/500, Loss: 0.1807, Validation Loss: 0.4419, Validation Accuracy: 0.8611\n",
            "Epoch 464/500, Loss: 0.1761, Validation Loss: 0.4029, Validation Accuracy: 0.8617\n",
            "Epoch 465/500, Loss: 0.1809, Validation Loss: 0.4084, Validation Accuracy: 0.8592\n",
            "Epoch 466/500, Loss: 0.1781, Validation Loss: 0.3999, Validation Accuracy: 0.8673\n",
            "Epoch 467/500, Loss: 0.1782, Validation Loss: 0.4002, Validation Accuracy: 0.8662\n",
            "Epoch 468/500, Loss: 0.1730, Validation Loss: 0.4132, Validation Accuracy: 0.8590\n",
            "Epoch 469/500, Loss: 0.1778, Validation Loss: 0.4171, Validation Accuracy: 0.8597\n",
            "Epoch 470/500, Loss: 0.1790, Validation Loss: 0.3980, Validation Accuracy: 0.8639\n",
            "Epoch 471/500, Loss: 0.1741, Validation Loss: 0.3905, Validation Accuracy: 0.8624\n",
            "Epoch 472/500, Loss: 0.1780, Validation Loss: 0.4018, Validation Accuracy: 0.8585\n",
            "Epoch 473/500, Loss: 0.1791, Validation Loss: 0.4029, Validation Accuracy: 0.8653\n",
            "Epoch 474/500, Loss: 0.1780, Validation Loss: 0.3996, Validation Accuracy: 0.8619\n",
            "Epoch 475/500, Loss: 0.1772, Validation Loss: 0.4069, Validation Accuracy: 0.8583\n",
            "Epoch 476/500, Loss: 0.1811, Validation Loss: 0.4144, Validation Accuracy: 0.8568\n",
            "Epoch 477/500, Loss: 0.1818, Validation Loss: 0.4160, Validation Accuracy: 0.8575\n",
            "Epoch 478/500, Loss: 0.1788, Validation Loss: 0.4015, Validation Accuracy: 0.8626\n",
            "Epoch 479/500, Loss: 0.1777, Validation Loss: 0.3987, Validation Accuracy: 0.8616\n",
            "Epoch 480/500, Loss: 0.1755, Validation Loss: 0.4074, Validation Accuracy: 0.8607\n",
            "Epoch 481/500, Loss: 0.1756, Validation Loss: 0.4011, Validation Accuracy: 0.8639\n",
            "Epoch 482/500, Loss: 0.1727, Validation Loss: 0.4155, Validation Accuracy: 0.8597\n",
            "Epoch 483/500, Loss: 0.1745, Validation Loss: 0.4171, Validation Accuracy: 0.8594\n",
            "Epoch 484/500, Loss: 0.1755, Validation Loss: 0.4115, Validation Accuracy: 0.8600\n",
            "Epoch 485/500, Loss: 0.1802, Validation Loss: 0.4147, Validation Accuracy: 0.8602\n",
            "Epoch 486/500, Loss: 0.1761, Validation Loss: 0.3999, Validation Accuracy: 0.8629\n",
            "Epoch 487/500, Loss: 0.1749, Validation Loss: 0.4097, Validation Accuracy: 0.8612\n",
            "Epoch 488/500, Loss: 0.1756, Validation Loss: 0.4196, Validation Accuracy: 0.8602\n",
            "Epoch 489/500, Loss: 0.1747, Validation Loss: 0.3891, Validation Accuracy: 0.8612\n",
            "Epoch 490/500, Loss: 0.1742, Validation Loss: 0.4040, Validation Accuracy: 0.8582\n",
            "Epoch 491/500, Loss: 0.1757, Validation Loss: 0.4183, Validation Accuracy: 0.8692\n",
            "Epoch 492/500, Loss: 0.1714, Validation Loss: 0.4256, Validation Accuracy: 0.8592\n",
            "Epoch 493/500, Loss: 0.1741, Validation Loss: 0.4314, Validation Accuracy: 0.8560\n",
            "Epoch 494/500, Loss: 0.1778, Validation Loss: 0.4178, Validation Accuracy: 0.8621\n",
            "Epoch 495/500, Loss: 0.1762, Validation Loss: 0.3931, Validation Accuracy: 0.8663\n",
            "Epoch 496/500, Loss: 0.1744, Validation Loss: 0.4042, Validation Accuracy: 0.8614\n",
            "Epoch 497/500, Loss: 0.1763, Validation Loss: 0.3840, Validation Accuracy: 0.8646\n",
            "Epoch 498/500, Loss: 0.1739, Validation Loss: 0.4002, Validation Accuracy: 0.8680\n",
            "Epoch 499/500, Loss: 0.1714, Validation Loss: 0.4463, Validation Accuracy: 0.8614\n",
            "Epoch 500/500, Loss: 0.1735, Validation Loss: 0.4169, Validation Accuracy: 0.8604\n",
            "Model saved to ensemble_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSyeagbOD4rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e7bGZvcuQrZ",
        "outputId": "0bec094a-949f-4dfa-bc7c-1633fe68e189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade setuptools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "zZeydGOPuvFp",
        "outputId": "9f9fa597-fbb9-443c-fbd8-ec4e4b776dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Using cached setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-70.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "acb24d0372334522b8afab172526dd03"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l6KvpuPsD6iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define constants\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "NUM_CLASSES = 49\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = '/content/drive/MyDrive/ANSYS/VRL_challenge_PAR1/VRL_challenge_PAR/'\n",
        "test_images_folder = os.path.join(drive_base_path, 'test_images')  # Folder containing test images\n",
        "\n",
        "# List all test image files\n",
        "test_image_names = [f.split('.')[0] for f in os.listdir(test_images_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Custom Dataset for Test Data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_names, images_folder, transform=None):\n",
        "        self.image_names = image_names\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.images_folder, f\"{img_name}.jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create DataLoader for test data\n",
        "test_dataset = TestDataset(test_image_names, test_images_folder, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the EnsembleModel (same as used in training)\n",
        "class PretrainedDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PretrainedDenseNet, self).__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class EnsembleModel(nn.Module):\n",
        "    def __init__(self, densenet_model, simplecnn_model):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.densenet_model = densenet_model\n",
        "        self.simplecnn_model = simplecnn_model\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(NUM_CLASSES * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, NUM_CLASSES),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        densenet_output = self.densenet_model(x)\n",
        "        simplecnn_output = self.simplecnn_model(x)\n",
        "        combined_output = torch.cat((densenet_output, simplecnn_output), dim=1)\n",
        "        return self.classifier(combined_output)\n",
        "\n",
        "# Instantiate the models\n",
        "densenet_model = PretrainedDenseNet(NUM_CLASSES).to(DEVICE)\n",
        "simplecnn_model = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# Instantiate the ensemble model\n",
        "ensemble_model = EnsembleModel(densenet_model, simplecnn_model).to(DEVICE)\n",
        "\n",
        "# Load the trained ensemble model\n",
        "model_path = \"/content/ensemble_model.pth\"\n",
        "ensemble_model.load_state_dict(torch.load(model_path))\n",
        "ensemble_model.eval()\n",
        "\n",
        "# Function to make predictions on test data\n",
        "def predict(model, dataloader, threshold=0.5):\n",
        "    model.eval()\n",
        "    predictions = {}\n",
        "    with torch.no_grad():\n",
        "        for inputs, img_names in dataloader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.cpu().numpy()\n",
        "            binary_outputs = (outputs >= threshold).astype(int)\n",
        "            for img_name, output in zip(img_names, binary_outputs):\n",
        "                predictions[img_name] = output\n",
        "    return predictions\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = predict(model, test_loader)\n",
        "\n",
        "# Example: Print the predictions for the first few test images\n",
        "for img_name, output in list(predictions.items())[:5]:\n",
        "    print(f\"Image: {img_name}, Prediction: {output}\")\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predictions_df = pd.DataFrame.from_dict(predictions, orient='index')\n",
        "predictions_df.to_csv('binary_predictions.csv', header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEtzG86xEt7f",
        "outputId": "a674d943-4127-4028-f39a-7e95c029c229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 144, Prediction: [1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 0]\n",
            "Image: 24, Prediction: [1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0\n",
            " 0 0 0 1 1 0 1 0 1 0 0 0]\n",
            "Image: 124, Prediction: [1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 0 0 1 1 0 1 0 0 1 0 0]\n",
            "Image: 66, Prediction: [1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 1 0 1 1 0 0 0 0]\n",
            "Image: 107, Prediction: [1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 0 0 1 1 0 1 1 0 0 0 0]\n"
          ]
        }
      ]
    }
  ]
}